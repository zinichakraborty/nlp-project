{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80ae7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def normalize(s):\n",
    "    \"\"\"Normalizes a sentence by stripping and collapsing whitespace.\"\"\"\n",
    "    return \" \".join(s.strip().split())\n",
    "\n",
    "def get_sentence_list(story_string):\n",
    "    \"\"\"Splits a story string into a list of normalized sentences.\"\"\"\n",
    "    return [normalize(s) for s in story_string.split(' | ')]\n",
    "\n",
    "def calculate_adjacent_sentence_accuracy(csv_path):\n",
    "    \"\"\"\n",
    "    Calculates the Adjacent Sentence Accuracy (ASA) for the model outputs.\n",
    "    ASA measures the percentage of adjacent sentence pairs (Si, S_i+1) that are \n",
    "    correctly ordered according to the gold standard.\n",
    "    \"\"\"\n",
    "    \n",
    "    total_adjacent_pairs = 0\n",
    "    correct_adjacent_pairs = 0\n",
    "    total_stories = 0\n",
    "    \n",
    "    out_of_range_count = 0\n",
    "    wrong_num_sentences_count = 0\n",
    "\n",
    "    try:\n",
    "        with open(csv_path, encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            \n",
    "            for row in reader:\n",
    "                total_stories += 1\n",
    "                \n",
    "                gold_sentences = get_sentence_list(row['gold'])\n",
    "                pred_sentences = get_sentence_list(row['model_reordered'])\n",
    "                if any(\"INDEX_OUT_OF_RANGE\" in s for s in pred_sentences):\n",
    "                    out_of_range_count += 1\n",
    "                    continue\n",
    "                if len(pred_sentences) != len(gold_sentences):\n",
    "                    wrong_num_sentences_count += 1\n",
    "                    continue\n",
    "                \n",
    "                N = len(gold_sentences)\n",
    "                if N <= 1:\n",
    "                    continue \n",
    "                num_adjacent_pairs = N - 1\n",
    "                total_adjacent_pairs += num_adjacent_pairs\n",
    "                \n",
    "                for i in range(N - 1):\n",
    "                    pred_sentence_i = pred_sentences[i]\n",
    "                    pred_sentence_i_plus_1 = pred_sentences[i+1]\n",
    "                    \n",
    "                    try:\n",
    "                        gold_index_i = gold_sentences.index(pred_sentence_i)\n",
    "                        correct_next_sentence = gold_sentences[gold_index_i + 1]\n",
    "                        \n",
    "                        if pred_sentence_i_plus_1 == correct_next_sentence:\n",
    "                            correct_adjacent_pairs += 1\n",
    "                    \n",
    "                    except (ValueError, IndexError):\n",
    "                        pass\n",
    "                        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: CSV file not found at {csv_path}\")\n",
    "        return 0, -1, -1, -1, -1 \n",
    "    \n",
    "    asa_score = correct_adjacent_pairs / total_adjacent_pairs if total_adjacent_pairs > 0 else 0\n",
    "    return asa_score, correct_adjacent_pairs, total_adjacent_pairs, out_of_range_count, wrong_num_sentences_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c1c105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Adjacent Sentence Accuracy (ASA) Results ---\n",
      "GPT-5 Nano ASA: 0.6253 (6118 '/' 9784 pairs correct)\n",
      "LLaMA-3 ASA:    0.2507 (68593 '/' 273652 pairs correct)\n",
      "Qwen ASA:       0.7350 (13395 '/' 18224 pairs correct)\n",
      "----------------------------------------------\n",
      "Overall ASA:    0.2921 (88106 '/' 301660 pairs correct)\n",
      "\n",
      "Generated all-metrics comparison plot: full_comp.png\n"
     ]
    }
   ],
   "source": [
    "def visualize_all_metrics(models, asa_scores, pmr_scores, kendall_tau_scores):\n",
    "    \"\"\"\n",
    "    Generates a bar plot comparing PMR, Kendall Tau, and ASA.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = {\n",
    "        'Model': models,\n",
    "        'PMR': pmr_scores,\n",
    "        'ASA': asa_scores,\n",
    "        'Kendall_Tau': kendall_tau_scores,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    bar_width = 0.25\n",
    "    r1 = np.arange(len(df['Model']))\n",
    "    r2 = [x + bar_width for x in r1]\n",
    "    r3 = [x + bar_width for x in r2]\n",
    "\n",
    "    plt.bar(r1, df['PMR'], color='skyblue', width=bar_width, edgecolor='grey', label='PMR')\n",
    "    plt.bar(r2, df['ASA'], color='lightgreen', width=bar_width, edgecolor='grey', label='Adjacent Sentence Accuracy (ASA)')\n",
    "    plt.bar(r3, df['Kendall_Tau'], color='lightcoral', width=bar_width, edgecolor='grey', label='Average Kendall $\\\\tau$')\n",
    "    plt.xlabel('Model', fontweight='bold')\n",
    "    plt.ylabel('Score', fontweight='bold')\n",
    "    plt.xticks([r + bar_width for r in range(len(df['Model']))], df['Model'])\n",
    "    plt.title('Model Performance Comparison: PMR, ASA, and Kendall $\\\\tau$', fontweight='bold')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    output_path = 'full_comp.png'\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "    print(f\"\\nGenerated all-metrics comparison plot: {output_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    GPT_NANO_PATH = \"data/final_outputs/train_gpt5_nano_reordered.csv\"\n",
    "    LLAMA3_PATH = \"data/final_outputs/train_llama3_reordered.csv\"\n",
    "    QWEN_PATH = \"data/final_outputs/train_qwen_reordered.csv\"\n",
    "    \n",
    "    gpt_nano_asa, gpt_nano_matches, gpt_nano_total_pairs, _, _ = calculate_adjacent_sentence_accuracy(GPT_NANO_PATH)\n",
    "    llama3_asa, llama3_matches, llama3_total_pairs, _, _ = calculate_adjacent_sentence_accuracy(LLAMA3_PATH)\n",
    "    qwen_asa, qwen_matches, qwen_total_pairs, _, _ = calculate_adjacent_sentence_accuracy(QWEN_PATH)\n",
    "\n",
    "    overall_matches = gpt_nano_matches + llama3_matches + qwen_matches\n",
    "    overall_total_pairs = gpt_nano_total_pairs + llama3_total_pairs + qwen_total_pairs\n",
    "    overall_asa = overall_matches / overall_total_pairs if overall_total_pairs > 0 else 0\n",
    "\n",
    "    print(\"--- Adjacent Sentence Accuracy (ASA) Results ---\")\n",
    "    print(f\"GPT-5 Nano ASA: {gpt_nano_asa:.4f} ({gpt_nano_matches} '/' {gpt_nano_total_pairs} pairs correct)\")\n",
    "    print(f\"LLaMA-3 ASA:    {llama3_asa:.4f} ({llama3_matches} '/' {llama3_total_pairs} pairs correct)\")\n",
    "    print(f\"Qwen ASA:       {qwen_asa:.4f} ({qwen_matches} '/' {qwen_total_pairs} pairs correct)\")\n",
    "    print(f\"----------------------------------------------\")\n",
    "    print(f\"Overall ASA:    {overall_asa:.4f} ({overall_matches} '/' {overall_total_pairs} pairs correct)\")\n",
    "    \n",
    "    visualize_all_metrics(\n",
    "        models=['GPT-5 Nano', 'LLaMA-3', 'Qwen'],\n",
    "        asa_scores=[gpt_nano_asa, llama3_asa, qwen_asa],\n",
    "        pmr_scores=[0.4321, 0.0412, 0.5890], \n",
    "        kendall_tau_scores=[0.7253, 0.3449, 0.8361] \n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
