{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8df5a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "max_int = sys.maxsize\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(max_int)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        max_int = max_int // 2\n",
    "\n",
    "gold_stories = []\n",
    "with open(\"data/processed/train_processed.csv\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        gold = [' '.join(s.split()) for s in row['gold'].split('|')]\n",
    "        gold_stories.append(gold)\n",
    "\n",
    "gold_set = {tuple(sorted(story)): i for i, story in enumerate(gold_stories)}\n",
    "\n",
    "def clean_model_output(model_csv, cleaned_csv, bad_rows_csv):\n",
    "    cleaned_rows = []\n",
    "    bad_rows = []\n",
    "\n",
    "    with open(model_csv, encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            pred_raw = row['reordered_story']\n",
    "            pred = [' '.join(s.split()) for s in pred_raw.split('|')]\n",
    "\n",
    "            if len(pred) != 5:\n",
    "                bad_rows.append({**row, \"reason\": \"wrong sentence count\"})\n",
    "                continue\n",
    "\n",
    "            if any(s.count('.') > 1 for s in pred):\n",
    "                bad_rows.append({**row, \"reason\": \"merged or corrupted sentence\"})\n",
    "                continue\n",
    "\n",
    "            pred_key = tuple(sorted(pred))\n",
    "            if pred_key in gold_set:\n",
    "                gold_story_index = gold_set[pred_key]\n",
    "                original_gold_story = gold_stories[gold_story_index]\n",
    "                cleaned_rows.append({\n",
    "                    \"original_story\": ' | '.join(original_gold_story),\n",
    "                    \"reordered_story\": ' | '.join(pred)\n",
    "                })\n",
    "            else:\n",
    "                bad_rows.append({**row, \"reason\": \"not a permutation of any gold story\"})\n",
    "        \n",
    "    os.makedirs(\"data/cleaned\", exist_ok=True)\n",
    "\n",
    "    with open(cleaned_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"original_story\", \"reordered_story\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(cleaned_rows)\n",
    "\n",
    "    with open(bad_rows_csv, 'w', newline='', encoding='utf-8') as f:\n",
    "        if bad_rows:\n",
    "            writer = csv.DictWriter(f, fieldnames=list(bad_rows[0].keys()))\n",
    "            writer.writeheader()\n",
    "            writer.writerows(bad_rows)\n",
    "\n",
    "\n",
    "clean_model_output(\n",
    "    \"data/processed/train_reordered_pairs_gpt5_nano.csv\",\n",
    "    \"data/cleaned/train_cleaned_gpt5_nano.csv\",\n",
    "    \"data/cleaned/train_bad_gpt5_nano.csv\"\n",
    ")\n",
    "\n",
    "clean_model_output(\n",
    "    \"data/processed/train_reordered_pairs_llama3.csv\",\n",
    "    \"data/cleaned/train_cleaned_llama3.csv\",\n",
    "    \"data/cleaned/train_bad_llama3.csv\"\n",
    ")\n",
    "\n",
    "clean_model_output(\n",
    "    \"data/processed/train_reordered_pairs_qwen.csv\",\n",
    "    \"data/cleaned/train_cleaned_qwen.csv\",\n",
    "    \"data/cleaned/train_bad_qwen.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b4209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average gpt5 nano Kendall tau: 0.6959409594095943\n",
      "gpt5 nano dropped rows:  2377\n",
      "Average llama3 Kendall tau: 0.7600000000000003\n",
      "llama3 dropped rows:  63372\n",
      "Average qwen Kendall tau: 0.8255813953488369\n",
      "qwen dropped rows:  10438\n"
     ]
    }
   ],
   "source": [
    "from kendall_tau import compute_kendall_tau\n",
    "\n",
    "gpt5_nano_taus, gpt5_nano_dropped_rows = compute_kendall_tau(\"data/processed/train_processed.csv\", \"data/cleaned/train_cleaned_gpt5_nano.csv\")\n",
    "print(\"Average gpt5 nano Kendall tau:\", sum(gpt5_nano_taus)/len(gpt5_nano_taus))\n",
    "print(\"gpt5 nano dropped rows: \", gpt5_nano_dropped_rows)\n",
    "\n",
    "llama3_taus, llama3_dropped_rows = compute_kendall_tau(\"data/processed/train_processed.csv\", \"data/cleaned/train_cleaned_llama3.csv\")\n",
    "print(\"Average llama3 Kendall tau:\", sum(llama3_taus)/len(llama3_taus))\n",
    "print(\"llama3 dropped rows: \", llama3_dropped_rows)\n",
    "\n",
    "qwen_taus, qwen_dropped_rows = compute_kendall_tau(\"data/processed/train_processed.csv\", \"data/cleaned/train_cleaned_qwen.csv\")\n",
    "print(\"Average qwen Kendall tau:\", sum(qwen_taus)/len(qwen_taus))\n",
    "print(\"qwen dropped rows: \", qwen_dropped_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bc8197a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentence mismatches: [188, 272, 239, 206, 120]\n",
      "Average sentence accuracy per story: [0.8632727272727273, 0.8021818181818182, 0.8261818181818181, 0.8501818181818181, 0.9127272727272727]\n",
      "ORIG:  ['I asked for a drink afterwards, but he told me no', 'I was forced to do several push-ups']\n",
      "REORD: ['He told me to stop as soon as I fell on the floor', 'I was forced to do several push-ups']\n",
      "\n",
      "ORIG:  ['She sighed in frustration that she had ruined it', 'Picking it up, she put it back in the car']\n",
      "REORD: ['The soda hit the ground hard', 'Picking it up, she put it back in the car']\n",
      "\n",
      "ORIG:  ['She had been playing with his puppy before he got angry', 'She ran for blocks without looking back']\n",
      "REORD: ['Lucy was running from an angry old man', 'She ran for blocks without looking back']\n",
      "\n",
      "ORIG:  ['His doctor asked Max if he slept through the night regularly', \"Max couldn't remember the last time he had slept through the night\"]\n",
      "REORD: ['Max noticed he was always tired so he went to the doctor for help', 'His doctor asked Max if he slept through the night regularly']\n",
      "\n",
      "ORIG:  ['His college textbooks were going to cost over 500 dollars', 'He knew that a similar amount would be expected in future quarters']\n",
      "REORD: [\"Joshua couldn't afford the assigned textbooks\", 'He knew that a similar amount would be expected in future quarters']\n",
      "\n",
      "ORIG:  [\"But now it has a key-scratch along the driver's side\", 'Andrew said a girl from his job calls him a lot for rides to work']\n",
      "REORD: ['His girlfriend complained because he lets another girl in his car', 'Andrew said a girl from his job calls him a lot for rides to work']\n",
      "\n",
      "ORIG:  ['They came in the mail a week later', 'They were covered in pictures of little animals']\n",
      "REORD: ['They came in the mail a week later', 'I squealed with delight when I saw them']\n",
      "\n",
      "ORIG:  ['Each day, Stu pedaled a bike ten miles to and from work', 'While his peers suffered health woes, Stu was as fit as a teen']\n",
      "REORD: ['Each day, Stu pedaled a bike ten miles to and from work', 'When Stu retired, many of his buddies were already dead']\n",
      "\n",
      "ORIG:  ['He always ate a lot of junk food', 'He was gaining a lot of weight']\n",
      "REORD: ['He was gaining a lot of weight', 'Tony wanted to cleanse his body']\n",
      "\n",
      "ORIG:  ['He had prepared several sandwiches and a pitcher of lemonade', 'Before they had a chance to eat, a large noise startled them']\n",
      "REORD: ['Brad was on a picnic with his family', 'Before they had a chance to eat, a large noise startled them']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from story_position_acc import count_sentence_mismatches, get_sentence_2_3_mismatches\n",
    "\n",
    "mismatches = count_sentence_mismatches(\"data/processed/train_reordered_pairs.csv\")\n",
    "print(\"Total sentence mismatches:\", mismatches)\n",
    "print(\"Average sentence accuracy per story:\", [(1375-m) / 1375 for m in mismatches])\n",
    "\n",
    "examples = get_sentence_2_3_mismatches(\"data/processed/train_reordered_pairs.csv\", k=10)\n",
    "for e in examples:\n",
    "    print(\"ORIG: \", e[\"orig\"])\n",
    "    print(\"REORD:\", e[\"reord\"])\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
